## User Story 002 – Pre-Award Director Ensures Quality

**Role**: Director, Department of Pediatrics Pre-Award Office  
**Need**: Oversee biannual tool runs, spot-check output integrity, and confirm staff confidence in the workflow.  
**Benefit**: Replace unreliable university-wide mailers and ad-hoc searches with vetted foundation matches faculty can trust.

### Narrative
As the Pre-Award director, I want transparent access to division-level opportunity lists and clear run logs so I can validate accuracy, coach staff, and report impact to the chair with confidence.

### Problem Today
- University-wide foundation mailers rarely align with pediatric research priorities.  
- Faculty resort to hit-or-miss personal searching, yielding inconsistent results.  
- Director lacks visibility into any matching logic, making quality assurance impossible.

### Success Signals
- Director can randomly audit output and trace every recommendation back to faculty keywords.  
- Pre-Award staff run the tool independently and attest to its ease of use.  
- Faculty feedback affirms that lists are relevant, comprehensive, and ready for action.  
- Tool execution history supports director’s updates to the chair on progress.

### Acceptance Criteria
1. Tool captures run metadata (who, when, divisions processed) accessible to the director.  
2. Director view includes keyword-to-opportunity mappings for sampling and validation.  
3. Workflow documentation enables staff to execute start-to-finish without director intervention.  
4. Outputs can be annotated with director comments or follow-up notes before distribution.  
5. System flags gaps (e.g., divisions with missing keywords) for director follow-up.

### Open Questions
- Preferred format for audit logs (dashboard, downloadable report, shared spreadsheet?).  
- Should the director receive automated prompts after each run for review and sign-off?
